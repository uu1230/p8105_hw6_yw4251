---
title: "p8105_hw6_yw4251"
author: "You Wu"
date: 2023-12-02
output: github_document
---
# Problem 0
Load Necessary Packages.
```{r}
library(tidyverse)
library(purrr)
library(ggridges)
library(modelr)
knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = .8,
  out.width = "90%"
)
```

# Problem 2
Load the dataset.
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
weather_df
```

Finish the bootstrap.
```{r}
bootstrap_analysis=
  weather_df|>
  bootstrap(n = 5000)|>
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp,data=df)),
    result = map(models, broom::tidy),
    log_beta_product=map(result, ~log(.x$estimate[2] * .x$estimate[3])),
    r.squared=map(models, ~broom::glance(.x)$r.squared)
    )|>
  select(-result)|>
  unnest(c(log_beta_product, r.squared))
bootstrap_analysis
```

Estimate of R^2. 
```{r}
quantiles=quantile(bootstrap_analysis$r.squared,c(0.025, 0.975))
quantiles
ggplot(bootstrap_analysis,aes(r.squared))+
  geom_density(fill = "#ADD8E6", alpha = 0.7)+
  geom_vline(xintercept = quantiles[1], linetype = "dashed", color = "#00008B", size = 1) +
  geom_vline(xintercept = quantiles[2], linetype = "dashed", color = "#00008B", size = 1) +
  labs(
    title = "Distribution of R Squared with 95% Confidence Interval",
    x = "R Squared",
    y = "Density"
  )+
  theme_minimal()
```

The plot illustrates a symmetric distribution of the R-squared statistic. R-squared values cluster tightly around 0.91, suggesting the model explains approximately 91% of the variance in the data, on average. The high density around the peak indicates that most R-squared values are close to the mean, signifying consistent performance of the model. The 95% confidence interval shows the range where the true R-squared value is likely to fall.

Estimate of log(β̂1 * β̂2). By calculation, `r mean(is.na(bootstrap_analysis$log_beta_product))*100`% of log(β̂1 * β̂2) are `NA`values. This high proportion of NA values primarily occurs because the product of 
β̂1 * β̂2 is less than 0, with β̂2 being the main contributing factor.
```{r}
quantiles=quantile(bootstrap_analysis$log_beta_product,c(0.025, 0.975),na.rm=TRUE)
quantiles
ggplot(bootstrap_analysis,aes(log_beta_product))+
  geom_density(fill = "#ADD8E6", alpha = 0.7)+
  geom_vline(xintercept = quantiles[1], linetype = "dashed", color = "#00008B", size = 1) +
  geom_vline(xintercept = quantiles[2], linetype = "dashed", color = "#00008B", size = 1) +
  labs(
    title = "Distribution of log(β̂1 * β̂2) with 95% Confidence Interval",
    x = "log(β̂1 * β̂2)",
    y = "Density"
    )+
  theme_minimal()
```

This plot is left skewed, indicating that most values of the log product are small (closer to zero).The peak of the density is negative and close to zero. The confidence interval suggests where the true log(product) value lies with 95% certainty, not crossing into positive values.

# Problem 3
Load and tidy the dataset. 
```{r}
bw=read_csv("data/birthweight.csv")|>
  janitor::clean_names()|>
  mutate(babysex=as.factor(babysex),
         frace=as.factor(frace),
         malform=as.factor(malform),
         mrace=as.factor(mrace))
anyNA(bw)
bw
```

The dataset contains `r nrow(bw)` observations across `r ncol(bw)` variables with no missing values. In the investigation, i want to investigate the impact of several key factors on the weight of a newborn, as measured in grams (bwt): the sex of the baby, the weight of the mother at the time of delivery in pounds, the family's monthly income, the gestational age in weeks, the presence or absence of malformations, the age of the mother at the time of delivery, the races of the mother and father, the average number of cigarettes the mother smoked daily during pregnancy, and the weight gained by the mother during pregnancy in pounds. My investigation aims to elucidate how these variables collectively influence the birth weight of a child. This approach aligns with established research `Factors Affecting Birth Weight of a Newborn – A Community Based Study in Rural Karnataka, India` [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3390317/]. (Metgud et al., 2012)
```{r}
fit=lm(bwt~babysex+delwt+fincome+gaweeks+malform+momage+mrace+frace+smoken+wtgain,data=bw)
fit|>
  summary()
```

### Key Findings from the Regression Model:
**Non-Significant Predictors**: the family's monthly income (fincome), the races of the mother and father, the age of the mother at the time of delivery(momage).

**Significant Predictors**: baby's sex (babysex), delivery weight (delwt), gestational weeks (gaweeks), mother's race (mrace2), and smoking status (smoken). 

The model explains approximately 32.54% of the variability in birthweight (adjusted R-squared: 0.323) and is statistically significant (F-statistic: 139.1, p-value: < 2.2e-16). The significant predictors show both positive and negative relationships with birthweight. For example, baby's sex and smoking status negatively influence birthweight, while delivery weight, gestational weeks, and weight gain during pregnancy positively affect it.

```{r}
bw|>
  modelr::add_residuals(fit,var = "pred") |>
  modelr::add_predictions(fit,var = "resid") |>
  ggplot(aes(x=pred,y=resid))+
  geom_point(color="#6C71C4",alpha=0.5)+
  geom_smooth(se = F, color = "red", method = "lm")+
  labs(x = "Fitted Values", y = "Residuals", title = "Residuals vs. Fitted Values")+
  theme_minimal()
```

Modify my model by emitting non-significant variables and fit other two models.
```{r}
my_model=lm(bwt~babysex+delwt+gaweeks+malform+mrace+smoken+wtgain,data=bw)
compmodel1=lm(bwt ~ gaweeks + blength, data = bw)
compmodel2= lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = bw)
```

Make comparison in terms of the cross-validated prediction error.
```{r}
cv_df=
  crossv_mc(bw,100)|>
   mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df=
  cv_df|>
  mutate(
    my_model  = map(train,~lm(bwt~babysex+delwt+gaweeks+malform+mrace+smoken+wtgain, data = .x)),
    compmodel1  = map(train, ~lm(bwt ~ gaweeks + blength, data = .x)),
    compmodel2  = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = .x)))|>
  mutate(
    rmse_my_model = map2_dbl(my_model, test, ~rmse(model = .x,data = .y)),
    rmse_compmodel1 = map2_dbl(compmodel1, test, ~rmse(model = .x,data = .y)),
    rmse_compmodel2 = map2_dbl(compmodel2, test, ~rmse(model = .x,data = .y)))
```

Make a violin Plot for comparison.
```{r}
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse,fill = model)) + 
  geom_violin()+
  scale_fill_brewer(palette = "Pastel2") +
  labs(x = "Model", y = "RMSE (Root Mean Square Error)", title = "Comparison of Model RMSEs") +
  theme_minimal()+
  theme(legend.position = "none")
```

The violin plot suggests that compmodel2: One using head circumference, length, sex, and all interactions (including the three-way interaction) between these has the most consistent and lowest RMSE, which indicates best model performance.
